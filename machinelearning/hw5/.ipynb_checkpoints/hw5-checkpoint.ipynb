{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471f693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "patientdata = []\n",
    "for filenum in range(1, 71):\n",
    "    patientnum = 'Patient Number ' + str(filenum)\n",
    "    if filenum < 10:\n",
    "        with open(\"C:\\\\Users\\\\Ayman\\\\Documents\\\\machinelearning\\\\hw5\\\\diabetes-data\\\\Diabetes-Data\\\\data-0\"+str(filenum), \"r\") as file:\n",
    "            for line in file:\n",
    "                fourth = str(line)\n",
    "                date = fourth[0:fourth.index('\\t')]\n",
    "                fourth = fourth.replace(date, '')\n",
    "                fourth = fourth.replace('\\t', '', 1)\n",
    "                time = fourth[0:fourth.index('\\t')]\n",
    "                fourth = fourth.replace(time, '')\n",
    "                fourth = fourth.replace('\\t', '', 1)\n",
    "                third = fourth[0:fourth.index('\\t')]\n",
    "                patientdata.append(float(third))\n",
    "    else:\n",
    "        with open(\"C:\\\\Users\\\\Ayman\\\\Documents\\\\machinelearning\\\\hw5\\\\diabetes-data\\\\Diabetes-Data\\\\data-\"+str(filenum), \"r\") as file:\n",
    "            for line in file:\n",
    "                fourth = str(line)\n",
    "                date = fourth[0:fourth.index('\\t')]\n",
    "                fourth = fourth.replace(date, '')\n",
    "                fourth = fourth.replace('\\t', '', 1)\n",
    "                time = fourth[0:fourth.index('\\t')]\n",
    "                fourth = fourth.replace(time, '')\n",
    "                fourth = fourth.replace('\\t', '', 1)\n",
    "                third = fourth[0:fourth.index('\\t')]\n",
    "                patientdata.append(float(third))\n",
    "\n",
    "df = pd.DataFrame(patientdata, columns=['col3'])#one hot encoding for the dataframe\n",
    "onehotencoded = pd.get_dummies(df['col3'], prefix='col3')\n",
    "datahot = pd.concat([df, onehotencoded], axis=1)\n",
    "\n",
    "#df_encoded.to_csv(\"C:\\\\Users\\\\Ayman\\\\Documents\\\\machinelearning\\\\hw4\\\\test_encoded.csv\", index=False)\n",
    "#print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c12b47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datahot = datahot.astype(int)#convering the booleans to int for 0 and 1\n",
    "print(datahot.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a0e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "def generatengrams(data, n):\n",
    "    ngrams_list = [tuple(data[i:i+n]) for i in range(len(data)-n+1)]\n",
    "    return ngrams_list\n",
    "\n",
    "ngrams = generatengrams(patientdata, n)#generating ngrams and placing those ngrams into the dataframe\n",
    "\n",
    "ngramsdf = pd.DataFrame(ngrams, columns=[f'Ngram_{i+1}' for i in range(n)])\n",
    "\n",
    "print(ngramsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156946ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def distance_matrix(data):#one hot data \n",
    "    num = len(data)\n",
    "    distancematrixx = np.zeros((num, num))\n",
    "    \n",
    "    for i in range(num):\n",
    "        print(i)#will go through all rows and columns to compute the distance for each\n",
    "        #if(i%50==0):\n",
    "            #print(i)\n",
    "        for j in range(i + 1, num):\n",
    "            distancematrixx[i, j] = np.sqrt(np.sum((data[i] - data[j])**2))  # Euclidean distance\n",
    "            distancematrixx[j, i] = distancematrixx[i, j]\n",
    "    return distancematrixx\n",
    "datamatrix = np.array(datahot.values)\n",
    "distancematrix = distance_matrix(datamatrix)\n",
    "'''\n",
    "for x in range(len(distancematrix)):\n",
    "    for xx in range(len(distancematrix[x])):\n",
    "        print(distancematrix[x][xx], end='   ')\n",
    "    print('')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26e6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(distancematrix)):\n",
    "    f = np.unique(distancematrix[x])\n",
    "    distancematrix[x] = np.resize(f, distancematrix[x].shape)#reshapes and handle duplicate distances from same way calculations\n",
    "    for xx in range(len(distancematrix[x])):\n",
    "        print(distancematrix[x][xx], end='   ')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a031033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def init_clusters(data):\n",
    "    return {data_id: [data_point] for data_id, data_point in enumerate(data)}\n",
    "\n",
    "def find_closest_clusters(distmatrix):\n",
    "    mindist = math.inf\n",
    "    closestclusters = None\n",
    "\n",
    "    for i in range(len(distmatrix)):\n",
    "        for j in range(i + 1, len(distmatrix)):\n",
    "            dist = distmatrix[i, j]#looks within the distance matrix for the closest clusters in that larger cluster set\n",
    "            if dist < mindist:\n",
    "                mindist, closestclusters = dist, (i, j)\n",
    "    return closestclusters\n",
    "\n",
    "def mergeclusters(clusters, ci_id, cj_id):\n",
    "    if ci_id not in clusters or cj_id not in clusters:\n",
    "        if ci_id == 0 or cj_id == 0:\n",
    "            return clusters #ignoring if removed\n",
    "\n",
    "    new_clusters = {0: clusters[ci_id] + clusters[cj_id]}\n",
    "    del clusters[ci_id]\n",
    "    del clusters[cj_id]#removing the clusters from library\n",
    "\n",
    "    for cluster_id, points in clusters.items():\n",
    "        new_clusters[len(new_clusters)] = points\n",
    "\n",
    "    return new_clusters\n",
    "\n",
    "def hierarchicalclustering(distmatrix, K):\n",
    "    clusters = init_clusters(distmatrix)\n",
    "    counter = 1\n",
    "    while len(clusters.keys()) > K:\n",
    "        print(f\"Iteration {counter}: Number of clusters = {len(clusters)}\")#main caller for other functions that will check if it has reached desired K\n",
    "        closestclusters = find_closest_clusters(distmatrix)\n",
    "        clusters = mergeclusters(clusters, *closestclusters)\n",
    "        counter+=1\n",
    "    return clusters\n",
    "\n",
    "\n",
    "# Usage\n",
    "K = 500  # Set your desired number of clusters\n",
    "finalclusters = hierarchicalclustering(distancematrix, K)\n",
    "print(finalclusters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0402558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_clusters(data):\n",
    "    return {data_id: [data_point] for data_id, data_point in enumerate(data)}\n",
    "\n",
    "def find_closest_clusters(distmatrix):\n",
    "    min_dist = math.inf\n",
    "    closest_clusters = None\n",
    "\n",
    "    for i in range(len(distmatrix)):\n",
    "        for j in range(i + 1, len(distmatrix[0])):  \n",
    "            dist = distmatrix[i, j]\n",
    "            if dist < min_dist:\n",
    "                min_dist, closest_clusters = dist, (i, j)\n",
    "    return closest_clusters\n",
    "\n",
    "def mergeclusters(clusters, ci_id, cj_id):\n",
    "    if ci_id not in clusters or cj_id not in clusters:\n",
    "        if ci_id == 0 or cj_id == 0:\n",
    "            # Ignore merging with cluster 0, as it might have been removed\n",
    "            return clusters\n",
    "\n",
    "        # One or both of the clusters do not exist, handle the situation accordingly\n",
    "\n",
    "    new_clusters = {0: clusters[ci_id] + clusters[cj_id]}\n",
    "\n",
    "    # Remove the merged clusters from the dictionary\n",
    "    del clusters[ci_id]\n",
    "    del clusters[cj_id]\n",
    "\n",
    "    for cluster_id, points in clusters.items():\n",
    "        new_clusters[len(new_clusters)] = points\n",
    "\n",
    "    return new_clusters\n",
    "\n",
    "def hierarchicalclustering(distmatrix, K):\n",
    "    clusters = init_clusters(distmatrix)\n",
    "    counter = 1\n",
    "    while len(clusters.keys()) > K:\n",
    "        print(f\"Iteration {counter}: Number of clusters = {len(clusters)}\")\n",
    "        closest_clusters = find_closest_clusters(distmatrix)\n",
    "        clusters = mergeclusters(clusters, *closest_clusters)\n",
    "        counter += 1\n",
    "    return clusters\n",
    "\n",
    "def pca(data, num_components):\n",
    "   \n",
    "    mean = np.mean(data, axis=0)#mean centering\n",
    "    centered_data = data - mean\n",
    "    covariancematrix = np.cov(centered_data, rowvar=False)#covariance matrix calculation\n",
    "   \n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariancematrix) eigen calculation\n",
    "    sorted = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[sorted]#sorting into descending order\n",
    "    eigenvectors = eigenvectors[:, sorted]\n",
    "    selected_eigenvectors = eigenvectors[:, :num_components]\n",
    "\n",
    "    finaldata = np.dot(centered_data, selected_eigenvectors)#place into final\n",
    "\n",
    "    return finaldata\n",
    "\n",
    "\n",
    "K = 10 \n",
    "\n",
    "# Assuming 'distancematrix' is your original data matrix\n",
    "# Perform PCA to reduce dimensions to, for example, 2 components\n",
    "finaldata = pca(distancematrix, 3) #reduces the data\n",
    "\n",
    "finalclusters = hierarchicalclustering(finaldata, K)\n",
    "print(finalclusters)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
